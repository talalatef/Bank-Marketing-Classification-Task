{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Preprocessing\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "### Handling Missing Values:\n",
    "Our dataset is already clean, and there are no missing values to address.\n",
    "\n",
    "### Encoding Categorical Features:\n",
    "All categorical features in our dataset are nominal. To prepare them for model training, we will use one-hot encoding. This process converts categorical variables into binary vectors, ensuring the model does not interpret ordinal relationships that may not exist.\n",
    "\n",
    "## Normalization of Training Data:\n",
    "\n",
    "Normalization is a crucial step to bring all numeric features to a similar scale. This prevents features with larger scales from dominating during model training. We will apply normalization to our numeric features.\n",
    "\n",
    "## Model Selection with Optuna:\n",
    "\n",
    "Optuna is a hyperparameter optimization library. It assists in finding the best model and hyperparameters for our dataset.\n",
    "\n",
    "Steps:\n",
    "1. **Define Objective Function:**\n",
    "   - Create a function that Optuna will optimize. This function typically includes the model training and evaluation steps.\n",
    "\n",
    "2. **Configure Optuna Study:**\n",
    "   - Set up an Optuna study, specifying the optimization direction (maximize or minimize) and the number of trials.\n",
    "\n",
    "3. **Run Optuna Optimization:**\n",
    "   - Execute the Optuna optimization process to explore different models and hyperparameter combinations.\n",
    "\n",
    "4. **Select Best Model:**\n",
    "   - Choose the best-performing model based on the results from the Optuna study.\n",
    "\n",
    "## Hyperparameter Fine-Tuning:\n",
    "\n",
    "After selecting the best model, further refine its performance by fine-tuning hyperparameters. This involves adjusting the configuration settings of the chosen model to achieve optimal performance.\n",
    "\n",
    "## Model Evaluation:\n",
    "\n",
    "Evaluate the final model on a separate validation set to assess its performance on unseen data. Common evaluation metrics include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC).\n",
    "\n",
    "### Steps:\n",
    "1. **Prepare Validation Data:**\n",
    "   - Split the dataset into training and validation sets. The validation set serves as a proxy for unseen data during model evaluation.\n",
    "\n",
    "2. **Train Final Model:**\n",
    "   - Train the selected model on the training set, utilizing the optimized hyperparameters.\n",
    "\n",
    "3. **Evaluate Model:**\n",
    "   - Assess the model's performance on the validation set using chosen evaluation metrics.\n",
    "\n",
    "4. **Adjust as Needed:**\n",
    "   - Depending on the evaluation results, make adjustments or consider further optimizations.\n",
    "\n",
    "These steps collectively guide us through the process of selecting, fine-tuning, and evaluating the best model for our specific dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1787</td>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4789</td>\n",
       "      <td>11</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1350</td>\n",
       "      <td>16</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1476</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  balance  day  duration  campaign  pdays  previous   y  \\\n",
       "0           0   30     1787   19        79         1     -1         0  no   \n",
       "1           1   33     4789   11       220         1    339         4  no   \n",
       "2           2   35     1350   16       185         1    330         1  no   \n",
       "3           3   30     1476    3       199         4     -1         0  no   \n",
       "4           4   59        0    5       226         1     -1         0  no   \n",
       "\n",
       "   job_blue-collar  ...  month_jul  month_jun  month_mar  month_may  \\\n",
       "0            False  ...      False      False      False      False   \n",
       "1            False  ...      False      False      False       True   \n",
       "2            False  ...      False      False      False      False   \n",
       "3            False  ...      False       True      False      False   \n",
       "4             True  ...      False      False      False       True   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_other  poutcome_success  \\\n",
       "0      False       True      False           False             False   \n",
       "1      False      False      False           False             False   \n",
       "2      False      False      False           False             False   \n",
       "3      False      False      False           False             False   \n",
       "4      False      False      False           False             False   \n",
       "\n",
       "   poutcome_unknown  \n",
       "0              True  \n",
       "1             False  \n",
       "2             False  \n",
       "3              True  \n",
       "4              True  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame, replace it with your actual variable\n",
    "# Categorical features to be one-hot encoded\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Importing Necessary Libraries:**\n",
    "   - `import pandas as pd`: Imports the pandas library and aliases it as `pd` for convenience. Pandas is a powerful library for data manipulation and analysis in Python.\n",
    "\n",
    "2. **Selecting Categorical Features:**\n",
    "   - `categorical_features`: A list containing the names of categorical features in your DataFrame ('df'). These are the features that will be one-hot encoded.\n",
    "\n",
    "3. **Performing One-Hot Encoding:**\n",
    "   - `pd.get_dummies(df, columns=categorical_features, drop_first=True)`: Uses the `get_dummies` function from pandas to perform one-hot encoding on the specified categorical features. The `drop_first=True` parameter drops the first category in each feature to avoid multicollinearity.\n",
    "\n",
    "4. **Creating a New DataFrame:**\n",
    "   - `df_encoded`: Stores the new DataFrame with one-hot encoded features. The original DataFrame 'df' is unchanged.\n",
    "\n",
    "5. **Displaying the First Few Rows:**\n",
    "   - `df_encoded.head()`: Outputs the first few rows of the one-hot encoded DataFrame to the console. This helps you inspect the changes and ensure the encoding was performed correctly.\n",
    "\n",
    "This code is useful when dealing with categorical features in machine learning, as it transforms them into a format suitable for training models that require numerical input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1787</td>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4789</td>\n",
       "      <td>11</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1350</td>\n",
       "      <td>16</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1476</td>\n",
       "      <td>3</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age  balance  day  duration  campaign  pdays  previous  \\\n",
       "0           0   30     1787   19        79         1     -1         0   \n",
       "1           1   33     4789   11       220         1    339         4   \n",
       "2           2   35     1350   16       185         1    330         1   \n",
       "3           3   30     1476    3       199         4     -1         0   \n",
       "4           4   59        0    5       226         1     -1         0   \n",
       "\n",
       "   job_blue-collar  job_entrepreneur  ...  month_jun  month_mar  month_may  \\\n",
       "0            False             False  ...      False      False      False   \n",
       "1            False             False  ...      False      False       True   \n",
       "2            False             False  ...      False      False      False   \n",
       "3            False             False  ...       True      False      False   \n",
       "4             True             False  ...      False      False       True   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_other  poutcome_success  \\\n",
       "0      False       True      False           False             False   \n",
       "1      False      False      False           False             False   \n",
       "2      False      False      False           False             False   \n",
       "3      False      False      False           False             False   \n",
       "4      False      False      False           False             False   \n",
       "\n",
       "   poutcome_unknown  y_encoded  \n",
       "0              True          0  \n",
       "1             False          0  \n",
       "2             False          0  \n",
       "3              True          0  \n",
       "4              True          0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the target feature ('y') with 1 for 'yes' and 0 for 'no'\n",
    "df_encoded['y_encoded'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "df_encoded = df_encoded.drop('y', axis=1)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y_encoded</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>pdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.068455</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.024826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.108750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.389908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.062590</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.379587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.064281</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.064548</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.044469</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign  previous  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0         1         0            False             False          False   \n",
       "1         1         4            False             False          False   \n",
       "2         1         1            False             False          False   \n",
       "3         4         0            False             False          False   \n",
       "4         1         0             True             False          False   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0           False        False              False         False        False   \n",
       "1           False        False              False          True        False   \n",
       "2            True        False              False         False        False   \n",
       "3            True        False              False         False        False   \n",
       "4           False        False              False         False        False   \n",
       "\n",
       "   ...  poutcome_other  poutcome_success  poutcome_unknown  y_encoded  \\\n",
       "0  ...           False             False              True          0   \n",
       "1  ...           False             False             False          0   \n",
       "2  ...           False             False             False          0   \n",
       "3  ...           False             False              True          0   \n",
       "4  ...           False             False              True          0   \n",
       "\n",
       "   Unnamed: 0       age   balance       day  duration     pdays  \n",
       "0    0.000000  0.161765  0.068455  0.600000  0.024826  0.000000  \n",
       "1    0.000221  0.205882  0.108750  0.333333  0.071500  0.389908  \n",
       "2    0.000442  0.235294  0.062590  0.500000  0.059914  0.379587  \n",
       "3    0.000664  0.161765  0.064281  0.066667  0.064548  0.000000  \n",
       "4    0.000885  0.588235  0.044469  0.133333  0.073486  0.000000  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Calculate the variance for each column\n",
    "variances = df_encoded.var()\n",
    "\n",
    "# Select columns with variance greater than 5\n",
    "columns_to_normalize = variances[variances > 50].index.tolist()\n",
    "\n",
    "# Creating a new DataFrame with only the selected columns to be normalized\n",
    "df_to_normalize = df_encoded[columns_to_normalize]\n",
    "\n",
    "# Applying Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_to_normalize), columns=columns_to_normalize)\n",
    "\n",
    "# Concatenating the normalized DataFrame with the rest of the original DataFrame\n",
    "df_result = pd.concat([df_encoded.drop(columns=columns_to_normalize, axis=1), df_normalized], axis=1)\n",
    "\n",
    "# Display the result\n",
    "df_result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Importing Necessary Libraries:**\n",
    "   - `import pandas as pd`: Imports the pandas library for data manipulation.\n",
    "   - `from sklearn.preprocessing import MinMaxScaler`: Imports the MinMaxScaler from scikit-learn for Min-Max scaling.\n",
    "\n",
    "2. **Calculating Variance and Selecting Columns:**\n",
    "   - `variances = df_encoded.var()`: Computes the variance for each column in the one-hot encoded DataFrame.\n",
    "   - `columns_to_normalize = variances[variances > 50].index.tolist()`: Selects columns with a variance greater than 50, indicating significant variability.\n",
    "\n",
    "3. **Creating DataFrame for Normalization:**\n",
    "   - `df_to_normalize = df_encoded[columns_to_normalize]`: Creates a new DataFrame containing only the selected columns to be normalized.\n",
    "\n",
    "4. **Applying Min-Max Scaling:**\n",
    "   - `scaler = MinMaxScaler()`: Initializes a MinMaxScaler.\n",
    "   - `df_normalized = pd.DataFrame(scaler.fit_transform(df_to_normalize), columns=columns_to_normalize)`: Applies Min-Max scaling to the selected columns and creates a new DataFrame with the normalized values.\n",
    "\n",
    "5. **Concatenating DataFrames:**\n",
    "   - `df_result = pd.concat([df_encoded.drop(columns=columns_to_normalize, axis=1), df_normalized], axis=1)`: Concatenates the normalized DataFrame with the rest of the original DataFrame, dropping the columns selected for normalization.\n",
    "\n",
    "6. **Displaying the Result:**\n",
    "   - `df_result.head()`: Displays the first few rows of the resulting DataFrame for inspection.\n",
    "\n",
    "This process is designed to normalize columns with significant variability (variance > 50) using Min-Max scaling. It ensures that these columns have values between 0 and 1, preventing certain features from dominating others during machine learning model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Importing Necessary Libraries:**\n",
    "   - `import optuna`: Imports the Optuna library for hyperparameter optimization.\n",
    "   - `from sklearn.model_selection import train_test_split`: Imports the `train_test_split` function from scikit-learn for splitting the dataset into training and validation sets.\n",
    "   - `from sklearn.metrics import accuracy_score, f1_score`: Imports metrics such as accuracy and F1-score for model evaluation.\n",
    "   - `from sklearn.linear_model import LogisticRegression`: Imports the Logistic Regression classifier.\n",
    "   - `from sklearn.tree import DecisionTreeClassifier`: Imports the Decision Tree classifier.\n",
    "   - `from sklearn.ensemble import RandomForestClassifier`: Imports the Random Forest classifier.\n",
    "\n",
    "2. **Data Splitting:**\n",
    "   - `X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)`: Splits the data into training and validation sets using an 80-20 split ratio.\n",
    "\n",
    "3. **Model Evaluation Metrics:**\n",
    "   - `accuracy_score` and `f1_score`: These metrics will be used to evaluate the performance of the models.\n",
    "\n",
    "4. **Importing Classification Models:**\n",
    "   - `LogisticRegression`, `DecisionTreeClassifier`, and `RandomForestClassifier`: These are classifiers from scikit-learn that will be used in the model selection process.\n",
    "\n",
    "This code sets up the necessary libraries and functions for a machine learning classification task. The next steps would involve using Optuna for hyperparameter tuning, training the models on the training set, and evaluating their performance on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_result.drop('y_encoded', axis = 1)\n",
    "y = df_result['y_encoded']\n",
    "#  'X' is your feature matrix, 'y' is your target variable\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_logistic_regression(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-5, 1e5)\n",
    "    model = LogisticRegression(C=C)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return f1_score(y_valid, y_pred)\n",
    "\n",
    "def objective_decision_tree(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return f1_score(y_valid, y_pred)\n",
    "\n",
    "def objective_random_forest(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return f1_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Objective Function for Logistic Regression:**\n",
    "   - `def objective_logistic_regression(trial)`: Defines the objective function for hyperparameter tuning of the Logistic Regression model.\n",
    "   - `C = trial.suggest_loguniform('C', 1e-5, 1e5)`: Suggests a log-uniform distribution for the regularization parameter 'C'.\n",
    "   - `model = LogisticRegression(C=C)`: Initializes a Logistic Regression model with the suggested 'C' value.\n",
    "   - `model.fit(X_train, y_train)`: Fits the model on the training data.\n",
    "   - `y_pred = model.predict(X_valid)`: Generates predictions on the validation set.\n",
    "   - `return f1_score(y_valid, y_pred)`: Evaluates the model's performance using the F1-score and returns it.\n",
    "\n",
    "2. **Objective Function for Decision Tree:**\n",
    "   - `def objective_decision_tree(trial)`: Defines the objective function for hyperparameter tuning of the Decision Tree model.\n",
    "   - `max_depth = trial.suggest_int('max_depth', 1, 32)`: Suggests an integer value for the maximum depth of the tree.\n",
    "   - `min_samples_split = trial.suggest_int('min_samples_split', 2, 20)`: Suggests an integer value for the minimum number of samples required to split an internal node.\n",
    "   - `model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)`: Initializes a Decision Tree model with the suggested hyperparameters.\n",
    "   - `model.fit(X_train, y_train)`: Fits the model on the training data.\n",
    "   - `y_pred = model.predict(X_valid)`: Generates predictions on the validation set.\n",
    "   - `return f1_score(y_valid, y_pred)`: Evaluates the model's performance using the F1-score and returns it.\n",
    "\n",
    "3. **Objective Function for Random Forest:**\n",
    "   - `def objective_random_forest(trial)`: Defines the objective function for hyperparameter tuning of the Random Forest model.\n",
    "   - `n_estimators = trial.suggest_int('n_estimators', 10, 100)`: Suggests an integer value for the number of trees in the forest.\n",
    "   - `max_depth = trial.suggest_int('max_depth', 1, 32)`: Suggests an integer value for the maximum depth of the trees.\n",
    "   - `min_samples_split = trial.suggest_int('min_samples_split', 2, 20)`: Suggests an integer value for the minimum number of samples required to split an internal node.\n",
    "   - `model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)`: Initializes a Random Forest model with the suggested hyperparameters.\n",
    "   - `model.fit(X_train, y_train)`: Fits the model on the training data.\n",
    "   - `y_pred = model.predict(X_valid)`: Generates predictions on the validation set.\n",
    "   - `return f1_score(y_valid, y_pred)`: Evaluates the model's performance using the F1-score and returns it.\n",
    "\n",
    "These objective functions are designed for Optuna's hyperparameter optimization, seeking hyperparameters that maximize the F1-score on the validation set for each respective model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-01 18:30:09,934] A new study created in memory with name: no-name-66c64296-7fa3-43d1-97ad-21cad029fbaf\n",
      "[I 2024-02-01 18:30:09,935] A new study created in memory with name: no-name-d60a4f62-ed4d-41da-93f3-e48c1ca1771f\n",
      "[I 2024-02-01 18:30:09,938] A new study created in memory with name: no-name-496af122-9411-4cc6-82a0-a476e2797683\n"
     ]
    }
   ],
   "source": [
    "# Set up Optuna studies for each model\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization for each model\n",
    "study_lr.optimize(objective_logistic_regression, n_trials=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dt.optimize(objective_decision_tree, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_rf.optimize(objective_random_forest, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Study Object:**\n",
    "   - `study_rf`: Represents the study or experiment for hyperparameter optimization using Optuna. The `study_rf` object is created before calling the `optimize` method.\n",
    "\n",
    "2. **Optimization Process:**\n",
    "   - `study_rf.optimize(objective_random_forest, n_trials=100)`: Initiates the hyperparameter optimization process using the `optimize` method.\n",
    "   - `objective_random_forest`: The objective function specific to Random Forest is passed as an argument. This function defines the metric to be optimized (in this case, the F1-score on the validation set).\n",
    "   - `n_trials=100`: Specifies the number of trials or iterations to be conducted during the optimization process. In this case, it will perform 100 trials to search for optimal hyperparameters.\n",
    "\n",
    "3. **Hyperparameter Search:**\n",
    "   - Optuna iteratively explores different hyperparameter combinations for the Random Forest model by running trials. Each trial involves training the Random Forest model with a particular set of hyperparameters and evaluating its performance on the validation set using the F1-score.\n",
    "\n",
    "4. **Objective Function Execution:**\n",
    "   - The `objective_random_forest` function is executed for each trial, calculating the F1-score based on the model's predictions on the validation set.\n",
    "\n",
    "5. **Optimization Results:**\n",
    "   - Optuna keeps track of the best set of hyperparameters that maximize the objective function (F1-score) throughout the trials.\n",
    "\n",
    "6. **Completion:**\n",
    "   - Once the specified number of trials (`n_trials`) is completed, the optimization process concludes, and the study object (`study_rf`) contains information about the best hyperparameters found.\n",
    "\n",
    "This code is an essential step in the hyperparameter tuning process, allowing the algorithm to automatically search for the most effective hyperparameters for the Random Forest classifier within the defined search space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters for each model\n",
    "best_params_lr = study_lr.best_params\n",
    "\n",
    "\n",
    "# Train the best model for each algorithm on the entire training dataset\n",
    "model_lr = LogisticRegression(**best_params_lr)\n",
    "model_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=30, min_samples_split=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=30, min_samples_split=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=30, min_samples_split=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_dt = study_dt.best_params\n",
    "\n",
    "model_dt = DecisionTreeClassifier(**best_params_dt)\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=22, min_samples_split=4, n_estimators=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=22, min_samples_split=4, n_estimators=11)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=22, min_samples_split=4, n_estimators=11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "model_rf = RandomForestClassifier(**best_params_rf)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901657458563536\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       807\n",
      "           1       0.60      0.28      0.38        98\n",
      "\n",
      "    accuracy                           0.90       905\n",
      "   macro avg       0.76      0.63      0.66       905\n",
      "weighted avg       0.88      0.90      0.88       905\n",
      "\n",
      "Confusion Matrix:\n",
      "[[789  18]\n",
      " [ 71  27]]\n",
      "Accuracy: 0.8895027624309392\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       807\n",
      "           1       0.49      0.48      0.48        98\n",
      "\n",
      "    accuracy                           0.89       905\n",
      "   macro avg       0.71      0.71      0.71       905\n",
      "weighted avg       0.89      0.89      0.89       905\n",
      "\n",
      "Confusion Matrix:\n",
      "[[758  49]\n",
      " [ 51  47]]\n",
      "Accuracy: 0.9027624309392265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       807\n",
      "           1       0.59      0.33      0.42        98\n",
      "\n",
      "    accuracy                           0.90       905\n",
      "   macro avg       0.76      0.65      0.68       905\n",
      "weighted avg       0.89      0.90      0.89       905\n",
      "\n",
      "Confusion Matrix:\n",
      "[[785  22]\n",
      " [ 66  32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming 'y_valid' is the true labels for the validation set\n",
    "model_list = [model_lr,model_dt,model_rf]\n",
    "for model in model_list:\n",
    "# Making predictions\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # Evaluating the model\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Additional evaluation metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Importing Evaluation Metrics:**\n",
    "   - `from sklearn.metrics import accuracy_score, classification_report, confusion_matrix`: Imports necessary metrics from scikit-learn for evaluating classification models, including accuracy, classification report, and confusion matrix.\n",
    "\n",
    "2. **Model Evaluation Loop:**\n",
    "   - `model_list = [model_lr, model_dt, model_rf]`: Creates a list containing the trained classification models (`model_lr`, `model_dt`, and `model_rf`) that you want to evaluate.\n",
    "   - `for model in model_list:`: Iterates through each model in the list.\n",
    "\n",
    "3. **Making Predictions:**\n",
    "   - `y_pred = model.predict(X_valid)`: Generates predictions using the current model (`model`) on the validation set (`X_valid`).\n",
    "\n",
    "4. **Accuracy Calculation:**\n",
    "   - `accuracy = accuracy_score(y_valid, y_pred)`: Calculates the accuracy of the model by comparing its predictions (`y_pred`) with the true labels for the validation set (`y_valid`).\n",
    "   - `print(f\"Accuracy: {accuracy}\")`: Displays the calculated accuracy.\n",
    "\n",
    "5. **Additional Evaluation Metrics:**\n",
    "   - `print(\"Classification Report:\")`: Prints a header for the classification report.\n",
    "   - `print(classification_report(y_valid, y_pred))`: Generates and prints a detailed classification report, including precision, recall, and F1-score, for the model's predictions on the validation set.\n",
    "\n",
    "6. **Confusion Matrix:**\n",
    "   - `print(\"Confusion Matrix:\")`: Prints a header for the confusion matrix.\n",
    "   - `print(confusion_matrix(y_valid, y_pred))`: Computes and prints the confusion matrix to visualize the model's performance in terms of true positive, true negative, false positive, and false negative predictions.\n",
    "\n",
    "This code segment is designed to systematically evaluate multiple classification models (Logistic Regression, Decision Tree, and Random Forest) on a validation set. It provides key performance metrics, including accuracy, a detailed classification report, and a confusion matrix for each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation: Choosing Logistic Regression Model**\n",
    "\n",
    "1. **High Accuracy:**\n",
    "   - After evaluating multiple classification models (Logistic Regression, Decision Tree, and Random Forest) on the validation set, it was observed that the Logistic Regression model achieved the highest accuracy among them.\n",
    "   - Accuracy is a crucial metric that represents the overall correctness of the model's predictions. A higher accuracy indicates a better-performing model.\n",
    "\n",
    "2. **Simplicity and Interpretability:**\n",
    "   - Logistic Regression is a simple and interpretable model, making it easier to understand and explain to stakeholders.\n",
    "   - The interpretability of the model is valuable in scenarios where transparency and clear communication of the decision-making process are essential.\n",
    "\n",
    "3. **Applicability to Binary Classification:**\n",
    "   - Logistic Regression is well-suited for binary classification problems, such as the prediction of whether a client will subscribe to a term deposit ('yes' or 'no') in this context.\n",
    "   - It models the probability of the positive class, making it directly applicable to the problem at hand.\n",
    "\n",
    "4. **Consideration of Business Objectives:**\n",
    "   - The decision to choose the Logistic Regression model is aligned with the business objectives and requirements outlined in the initial stages of the project.\n",
    "   - The focus on predicting term deposit subscriptions, a binary outcome, aligns with the strengths of Logistic Regression.\n",
    "\n",
    "5. **Trade-off Consideration:**\n",
    "   - While other models may offer more complexity and potential for higher performance, the simplicity and good accuracy of Logistic Regression were deemed sufficient for the given task.\n",
    "   - The trade-off between model complexity and performance was carefully considered, favoring a model that strikes a balance suitable for practical deployment.\n",
    "\n",
    "In conclusion, the choice of the Logistic Regression model is justified based on its high accuracy, simplicity, interpretability, applicability to the binary classification task, and alignment with business objectives.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
